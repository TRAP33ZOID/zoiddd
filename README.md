# ğŸ™ï¸ Zoid AI Support Agent

A production-ready, bilingual (English/Arabic) voice-enabled AI customer support agent built with Next.js, featuring real-time speech interaction and RAG-powered knowledge retrieval.

## âœ¨ Features

- ğŸ—£ï¸ **Real-time Voice Interaction**: Speech-to-Text and Text-to-Speech using Google Cloud APIs
- ğŸŒ **Bilingual Support**: Full English and Modern Standard Arabic (ar-SA) support
- ğŸ“š **RAG-Powered Knowledge Base**: Vector-based document retrieval using Supabase pgvector
- ğŸ¯ **Language-Aware Retrieval**: Automatic language filtering for context accuracy
- ğŸ“ **Text & Voice Chat**: Seamless switching between text and voice input
- ğŸ”„ **RTL Support**: Right-to-left text rendering for Arabic
- ğŸ“Š **Comprehensive Logging**: Built-in diagnostic infrastructure for monitoring

## ğŸ› ï¸ Tech Stack

- **Framework**: Next.js 16 (App Router)
- **AI Model**: Google Gemini 2.5 Flash
- **Embeddings**: text-embedding-004 (768 dimensions)
- **Vector Database**: Supabase with pgvector
- **Voice Services**: Google Cloud Speech-to-Text & Text-to-Speech
- **Frontend**: React 19, TailwindCSS, shadcn/ui
- **Language**: TypeScript

## ğŸ“‹ Prerequisites

Before you begin, ensure you have:

- **Node.js** 18+ installed
- **npm** or **yarn** package manager
- **Google Cloud Platform** account with:
  - Speech-to-Text API enabled
  - Text-to-Speech API enabled
  - Gemini API access
- **Supabase** account (free tier works)
- **Git** for version control

## ğŸš€ Setup Instructions

### 1. Clone the Repository

```bash
git clone <your-repo-url>
cd zoiddd
```

### 2. Install Dependencies

```bash
npm install
```

### 3. Set Up Environment Variables

Create a `.env.local` file in the root directory:

```env
# Google Gemini API
GEMINI_API_KEY=your_gemini_api_key_here

# Supabase Configuration
NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_anon_key_here
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key_here
```

**How to get these keys:**

#### Gemini API Key
1. Go to [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Create a new API key
3. Copy and paste into `.env.local`

#### Supabase Keys
1. Create a project at [Supabase](https://supabase.com)
2. Go to Project Settings â†’ API
3. Copy the **Project URL** and **anon public** key
4. Copy the **service_role** key (keep this secret!)

### 4. Set Up Google Cloud Credentials

#### 4.1 Create a Service Account

1. Go to [Google Cloud Console](https://console.cloud.google.com)
2. Create a new project or select existing one
3. Go to **IAM & Admin** â†’ **Service Accounts**
4. Click **Create Service Account**
5. Grant the following roles:
   - **Cloud Speech-to-Text API User**
   - **Cloud Text-to-Speech API User**
6. Create and download a **JSON key file**

#### 4.2 Add Credentials to Project

1. Rename the downloaded JSON file to `google-cloud-key.json`
2. Place it in the `lib/` directory:
   ```
   lib/google-cloud-key.json
   ```
3. **Important**: This file is already in `.gitignore` - never commit it to Git!

### 5. Configure Supabase Database

#### 5.1 Create the Documents Table

Run this SQL in your Supabase SQL Editor:

```sql
-- Enable pgvector extension
CREATE EXTENSION IF NOT EXISTS vector;

-- Create documents table
CREATE TABLE documents (
  id BIGSERIAL PRIMARY KEY,
  content TEXT NOT NULL,
  embedding vector(768),
  metadata JSONB DEFAULT '{}',
  language VARCHAR(10) DEFAULT 'en-US',
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Create index for vector similarity search
CREATE INDEX ON documents USING ivfflat (embedding vector_cosine_ops)
  WITH (lists = 100);

-- Create index for language filtering
CREATE INDEX idx_documents_language ON documents(language);
```

#### 5.2 Create the Match Documents Function

Run this SQL in your Supabase SQL Editor:

```sql
CREATE OR REPLACE FUNCTION match_documents(
  query_embedding vector(768),
  match_count int,
  language varchar DEFAULT 'en-US',
  filter jsonb DEFAULT '{}'
)
RETURNS TABLE (
  id bigint,
  content text,
  metadata jsonb,
  similarity float
)
LANGUAGE plpgsql
AS $$
#variable_conflict use_column
BEGIN
  RETURN query
  SELECT
    id,
    content,
    metadata,
    1 - (documents.embedding <=> query_embedding) AS similarity
  FROM documents
  WHERE documents.language = match_documents.language
    AND metadata @> filter
  ORDER BY documents.embedding <=> query_embedding
  LIMIT match_count;
END;
$$;
```

### 6. Upload Sample Knowledge Base (Optional)

Sample knowledge base files are provided in the `knowledge-bases/` directory:
- `sample-en.txt` - English content
- `sample-ar.txt` - Arabic content

**To upload:**
1. Start the dev server (see step 7)
2. Open the ingestion form in the app
3. Upload the sample files
4. The system will automatically:
   - Split text into chunks
   - Generate embeddings
   - Store in Supabase with language tags

### 7. Run the Development Server

```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) in your browser.

### 8. Grant Microphone Permissions

When prompted by your browser, allow microphone access to use voice features.

## ğŸ“ Project Structure

```
zoiddd/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ chat/          # Text chat endpoint
â”‚   â”‚   â”œâ”€â”€ voice/         # Voice interaction endpoint
â”‚   â”‚   â””â”€â”€ ingest/        # Document ingestion endpoint
â”‚   â”œâ”€â”€ globals.css        # Global styles
â”‚   â”œâ”€â”€ layout.tsx         # Root layout
â”‚   â””â”€â”€ page.tsx           # Home page
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ chat-interface.tsx # Main chat UI component
â”‚   â”œâ”€â”€ ingestion-form.tsx # Document upload component
â”‚   â””â”€â”€ ui/                # shadcn/ui components
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ gemini.ts          # Gemini AI client
â”‚   â”œâ”€â”€ voice.ts           # STT/TTS functions
â”‚   â”œâ”€â”€ rag.ts             # RAG retrieval logic
â”‚   â”œâ”€â”€ supabase.ts        # Supabase client
â”‚   â”œâ”€â”€ language.ts        # Language configuration
â”‚   â””â”€â”€ google-cloud-key.json # (YOU MUST CREATE THIS)
â”œâ”€â”€ knowledge-bases/       # Sample knowledge base files
â”œâ”€â”€ .env.local            # (YOU MUST CREATE THIS)
â””â”€â”€ PROJECT_HANDOVER.md   # Comprehensive technical documentation
```

## ğŸ¯ Usage

### Text Chat
1. Select language (English | Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©) from dropdown
2. Type your message in the input field
3. Press "Send" or Enter

### Voice Chat
1. Select your preferred language
2. Click the "Record" button
3. Speak your question clearly
4. Click "Send Recording"
5. The AI will respond with both text and audio

### Document Ingestion
1. Navigate to the ingestion page
2. Select language (en-US or ar-SA)
3. Upload a `.txt`, `.pdf`, or `.docx` file
4. The system will process and store the content

## ğŸ“š Documentation

- **[PROJECT_HANDOVER.md](PROJECT_HANDOVER.md)** - Comprehensive technical documentation including:
  - Complete development history (Phases 1-4A)
  - Architecture decisions
  - System dependencies
  - Known constraints
  - Future roadmap (Phases 4B-4E)
  - Testing protocols

## ğŸ” Security Notes

**Never commit these files:**
- `.env.local` (contains API keys)
- `lib/google-cloud-key.json` (contains service account credentials)

These are already in `.gitignore`, but always double-check before committing.

## ğŸ› Troubleshooting

### Microphone Not Working
- Check browser permissions (Settings â†’ Privacy â†’ Microphone)
- Try a different browser (Chrome/Firefox recommended)
- Ensure no other app is using the microphone

### STT/TTS Errors
- Verify Google Cloud credentials are correct
- Check that APIs are enabled in Google Cloud Console
- Review server logs for detailed error messages

### RAG Not Retrieving Context
- Ensure documents are uploaded with correct language tag
- Verify Supabase `match_documents()` function exists
- Check that knowledge base has content for the selected language

### Database Connection Issues
- Verify Supabase URL and keys in `.env.local`
- Check that the `documents` table exists
- Ensure pgvector extension is enabled

## ğŸ“Š Current Status

- âœ… Phase 1: Core RAG Chat Implementation
- âœ… Phase 2: Persistent Knowledge Base & Ingestion
- âœ… Phase 3: Voice Integration
- âœ… Phase 4A: Arabic Language Support (VERIFIED)
- ğŸš§ Phase 4B: Tool Use / Function Calling (Planned)
- ğŸš§ Phase 4C: Human Handoff System (Planned)
- ğŸš§ Phase 4D: Multi-Session Management (Planned)
- ğŸš§ Phase 4E: Production Hardening (Planned)

## ğŸ“ License

[Add your license here]

## ğŸ¤ Contributing

[Add contribution guidelines here]

## ğŸ“§ Contact

[Add contact information here]

---

**Built with â¤ï¸ for the MENA region**
